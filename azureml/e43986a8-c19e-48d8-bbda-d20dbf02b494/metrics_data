{"e43986a8-c19e-48d8-bbda-d20dbf02b494_2":{"weighted_accuracy":[0.9798987932009579],"log_loss":[0.2371733156187967],"f1_score_micro":[0.8919575113808801],"recall_score_micro":[0.8919575113808801],"AUC_macro":[0.8972833969624727],"norm_macro_recall":[0.07549083351393993],"precision_score_macro":[0.7669629755790798],"AUC_weighted":[0.8972833969624725],"f1_score_weighted":[0.8529604250555909],"average_precision_score_weighted":[0.9275679551566662],"precision_score_weighted":[0.8668102195794557],"precision_score_micro":[0.8919575113808801],"AUC_micro":[0.9671671567487409],"average_precision_score_macro":[0.7308217672707936],"recall_score_weighted":[0.8919575113808801],"balanced_accuracy":[0.53774541675697],"recall_score_macro":[0.53774541675697],"matthews_correlation":[0.20076482532468856],"f1_score_macro":[0.5432848047643966],"accuracy":[0.8919575113808801],"average_precision_score_micro":[0.9671641473023961]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_33":{"matthews_correlation":[0.5269062366413191],"precision_score_weighted":[0.9067413615217357],"norm_macro_recall":[0.47630995448710456],"average_precision_score_weighted":[0.9528812754593075],"average_precision_score_micro":[0.9805171046193448],"recall_score_weighted":[0.91350531107739],"AUC_micro":[0.9795687124235231],"average_precision_score_macro":[0.8142566687071048],"f1_score_weighted":[0.9091603275553164],"AUC_macro":[0.9443518256098486],"recall_score_micro":[0.91350531107739],"log_loss":[0.18416061132957412],"precision_score_macro":[0.7914385680963489],"precision_score_micro":[0.91350531107739],"f1_score_macro":[0.7610253560094269],"f1_score_micro":[0.91350531107739],"balanced_accuracy":[0.7381549772435523],"recall_score_macro":[0.7381549772435523],"weighted_accuracy":[0.9570400558220584],"accuracy":[0.91350531107739],"AUC_weighted":[0.9443518256098486]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_28":{"f1_score_macro":[0.7316518156558398],"precision_score_micro":[0.8968133535660091],"recall_score_weighted":[0.8968133535660091],"accuracy":[0.8968133535660091],"log_loss":[0.24977482290843903],"recall_score_macro":[0.7240199538017253],"average_precision_score_weighted":[0.9405120651365592],"weighted_accuracy":[0.9397132807451036],"balanced_accuracy":[0.7240199538017253],"AUC_micro":[0.9649732776704485],"average_precision_score_macro":[0.7686767277314295],"precision_score_macro":[0.7401167858284508],"average_precision_score_micro":[0.9580897752256542],"matthews_correlation":[0.4638575266967576],"AUC_macro":[0.9242739146461868],"f1_score_weighted":[0.895024369789806],"norm_macro_recall":[0.4480399076034507],"recall_score_micro":[0.8968133535660091],"f1_score_micro":[0.8968133535660091],"precision_score_weighted":[0.8934551416282733],"AUC_weighted":[0.9242739146461868]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_27":{"average_precision_score_weighted":[0.9411162587840349],"recall_score_macro":[0.6184733822731255],"average_precision_score_macro":[0.77183380124367],"matthews_correlation":[0.35291527312059223],"AUC_micro":[0.9725022278202362],"f1_score_macro":[0.6537672120667568],"precision_score_weighted":[0.8791609030873745],"log_loss":[0.24190016733770991],"recall_score_weighted":[0.8986342943854325],"AUC_weighted":[0.9237543229841046],"average_precision_score_micro":[0.9715126704294967],"f1_score_weighted":[0.8797235922503923],"AUC_macro":[0.9237543229841048],"weighted_accuracy":[0.9681906706384735],"precision_score_macro":[0.7628210396548182],"norm_macro_recall":[0.23694676454625108],"recall_score_micro":[0.8986342943854325],"accuracy":[0.8986342943854325],"f1_score_micro":[0.8986342943854325],"balanced_accuracy":[0.6184733822731255],"precision_score_micro":[0.8986342943854325]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_37":{"average_precision_score_weighted":[0.9544336057178775],"precision_score_macro":[0.8576441369103848],"matthews_correlation":[0.3469783097889264],"log_loss":[0.23300638971034912],"recall_score_weighted":[0.9028831562974203],"norm_macro_recall":[0.1683152819224707],"recall_score_macro":[0.5841576409612353],"average_precision_score_micro":[0.9784401789852246],"AUC_macro":[0.9453761899204776],"f1_score_micro":[0.9028831562974204],"f1_score_macro":[0.6168069963250686],"recall_score_micro":[0.9028831562974203],"balanced_accuracy":[0.5841576409612353],"f1_score_weighted":[0.8737429784287931],"AUC_weighted":[0.9453761899204776],"precision_score_weighted":[0.8945189129934737],"weighted_accuracy":[0.9820140803760838],"AUC_micro":[0.9772869639703327],"accuracy":[0.9028831562974203],"average_precision_score_macro":[0.82072234559292],"precision_score_micro":[0.9028831562974203]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_1":{"recall_score_macro":[0.7191727470931578],"f1_score_weighted":[0.9021127651963996],"precision_score_macro":[0.7723958081530135],"average_precision_score_micro":[0.9791945367231853],"accuracy":[0.9071320182094081],"recall_score_micro":[0.9071320182094081],"matthews_correlation":[0.488678780261868],"weighted_accuracy":[0.9537972210153172],"log_loss":[0.1874363495858499],"average_precision_score_macro":[0.8065229883244922],"recall_score_weighted":[0.9071320182094081],"norm_macro_recall":[0.43834549418631563],"f1_score_macro":[0.7416848907681176],"precision_score_weighted":[0.8991976076061607],"AUC_micro":[0.9781770788959222],"f1_score_micro":[0.9071320182094081],"AUC_weighted":[0.9392346349984347],"precision_score_micro":[0.9071320182094081],"balanced_accuracy":[0.7191727470931578],"AUC_macro":[0.9392346349984347],"average_precision_score_weighted":[0.9505970434373063]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_20":{"weighted_accuracy":[0.7003048069262952],"average_precision_score_micro":[0.8017219002097231],"precision_score_weighted":[0.8757110993587777],"AUC_macro":[0.8441572334383631],"AUC_weighted":[0.844157233438363],"f1_score_micro":[0.7047040971168437],"recall_score_weighted":[0.7047040971168437],"f1_score_weighted":[0.7579320774824435],"accuracy":[0.7047040971168437],"average_precision_score_macro":[0.7086399941492796],"AUC_micro":[0.8147297256845223],"f1_score_macro":[0.5845512548138593],"matthews_correlation":[0.29406957939934797],"balanced_accuracy":[0.7224236681874678],"precision_score_micro":[0.7047040971168437],"average_precision_score_weighted":[0.9153408993796978],"norm_macro_recall":[0.4448473363749357],"recall_score_macro":[0.7224236681874678],"precision_score_macro":[0.5971984211851311],"log_loss":[0.5435912178518293],"recall_score_micro":[0.7047040971168437]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_22":{"log_loss":[0.18369916239363407],"f1_score_micro":[0.90804248861912],"accuracy":[0.9080424886191198],"balanced_accuracy":[0.7445521601490792],"precision_score_weighted":[0.9037941765081041],"precision_score_macro":[0.7713193708024036],"AUC_micro":[0.978771624823559],"matthews_correlation":[0.5151766229945487],"f1_score_macro":[0.7569314175488706],"precision_score_micro":[0.9080424886191198],"average_precision_score_weighted":[0.9524128699963818],"weighted_accuracy":[0.9486327148396743],"recall_score_macro":[0.7445521601490792],"AUC_macro":[0.9409323382365744],"f1_score_weighted":[0.9056577488524223],"recall_score_micro":[0.9080424886191198],"average_precision_score_macro":[0.8139354179020992],"average_precision_score_micro":[0.9797430783492997],"norm_macro_recall":[0.4891043202981584],"recall_score_weighted":[0.9080424886191198],"AUC_weighted":[0.9409323382365743]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_31":{"AUC_weighted":[0.9419733739374303],"balanced_accuracy":[0.7433921092457678],"recall_score_micro":[0.9122913505311078],"average_precision_score_weighted":[0.9521900635506175],"precision_score_weighted":[0.9065237929615331],"weighted_accuracy":[0.954224463495085],"matthews_correlation":[0.527343824348664],"accuracy":[0.9122913505311078],"recall_score_macro":[0.7433921092457678],"f1_score_micro":[0.9122913505311078],"norm_macro_recall":[0.48678421849153564],"average_precision_score_macro":[0.812331116618507],"average_precision_score_micro":[0.9799857423567289],"AUC_micro":[0.9790151537829194],"precision_score_micro":[0.9122913505311078],"precision_score_macro":[0.7856414593106926],"f1_score_weighted":[0.9087923391639493],"log_loss":[0.20930962449208365],"f1_score_macro":[0.7621206659537194],"AUC_macro":[0.9419733739374304],"recall_score_weighted":[0.9122913505311078]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_14":{"matthews_correlation":[0.0],"average_precision_score_macro":[0.6953188595216155],"precision_score_micro":[0.8880121396054628],"AUC_micro":[0.9637563697237503],"weighted_accuracy":[0.9843450583187134],"f1_score_weighted":[0.8353395018439429],"precision_score_weighted":[0.788565560086672],"recall_score_weighted":[0.8880121396054628],"recall_score_micro":[0.8880121396054628],"average_precision_score_weighted":[0.9172112649539331],"average_precision_score_micro":[0.9623360859228542],"log_loss":[0.2585823526648921],"norm_macro_recall":[0.0],"precision_score_macro":[0.4440060698027314],"f1_score_macro":[0.4703423886834914],"recall_score_macro":[0.5],"AUC_macro":[0.8808287348081956],"accuracy":[0.8880121396054628],"balanced_accuracy":[0.5],"AUC_weighted":[0.8808287348081956],"f1_score_micro":[0.8880121396054628]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_17":{"f1_score_micro":[0.8959028831562974],"f1_score_weighted":[0.8872983183323412],"recall_score_micro":[0.8959028831562974],"precision_score_weighted":[0.8828667092689839],"norm_macro_recall":[0.34044275507690136],"log_loss":[0.23643746056692852],"AUC_micro":[0.9673447376237966],"balanced_accuracy":[0.6702213775384507],"weighted_accuracy":[0.9519334964197748],"average_precision_score_micro":[0.9677666071792572],"average_precision_score_macro":[0.7472044847997336],"precision_score_macro":[0.7379384630521975],"AUC_weighted":[0.9048174760626622],"f1_score_macro":[0.6959776900292433],"matthews_correlation":[0.402503232037343],"precision_score_micro":[0.8959028831562974],"accuracy":[0.8959028831562974],"recall_score_macro":[0.6702213775384507],"recall_score_weighted":[0.8959028831562974],"AUC_macro":[0.9048174760626623],"average_precision_score_weighted":[0.9332578963332194]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_10":{"weighted_accuracy":[0.9843450583187134],"norm_macro_recall":[0.0],"recall_score_macro":[0.5],"average_precision_score_macro":[0.7016074726950174],"accuracy":[0.8880121396054628],"recall_score_weighted":[0.8880121396054628],"matthews_correlation":[0.0],"f1_score_weighted":[0.8353395018439429],"balanced_accuracy":[0.5],"AUC_micro":[0.9644256138306764],"precision_score_macro":[0.4440060698027314],"AUC_weighted":[0.8841935770690583],"precision_score_micro":[0.8880121396054628],"f1_score_macro":[0.4703423886834914],"f1_score_micro":[0.8880121396054628],"average_precision_score_weighted":[0.9194693752776074],"average_precision_score_micro":[0.9644249253046102],"recall_score_micro":[0.8880121396054628],"log_loss":[0.2668620025641226],"precision_score_weighted":[0.788565560086672],"AUC_macro":[0.8841935770690584]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_30":{"precision_score_weighted":[0.8569628765038234],"average_precision_score_weighted":[0.9375328402171986],"matthews_correlation":[0.1280294158530881],"balanced_accuracy":[0.5172613722036059],"log_loss":[0.23625251121581806],"f1_score_macro":[0.5061736759270778],"average_precision_score_micro":[0.9726484016412681],"recall_score_weighted":[0.8892261001517451],"f1_score_weighted":[0.8436874763207629],"weighted_accuracy":[0.9815748806256229],"recall_score_micro":[0.8892261001517451],"AUC_weighted":[0.9180517813380458],"AUC_macro":[0.9180517813380458],"average_precision_score_macro":[0.7581904879192145],"accuracy":[0.8892261001517451],"norm_macro_recall":[0.034522744407211814],"precision_score_macro":[0.7374019158259453],"recall_score_macro":[0.5172613722036059],"precision_score_micro":[0.8892261001517451],"f1_score_micro":[0.8892261001517451],"AUC_micro":[0.9711833582404019]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_32":{"precision_score_micro":[0.9001517450682853],"recall_score_macro":[0.6737978538363648],"precision_score_weighted":[0.886943948194693],"balanced_accuracy":[0.6737978538363648],"recall_score_micro":[0.9001517450682853],"f1_score_micro":[0.9001517450682853],"f1_score_macro":[0.7032562687354458],"average_precision_score_weighted":[0.8652214735117361],"f1_score_weighted":[0.890835155837931],"weighted_accuracy":[0.9563492934920139],"AUC_macro":[0.7078575040705977],"matthews_correlation":[0.4201976930247987],"AUC_micro":[0.9132802033706287],"AUC_weighted":[0.7078575040705977],"recall_score_weighted":[0.9001517450682853],"precision_score_macro":[0.7539819930538448],"average_precision_score_macro":[0.6341066766698003],"norm_macro_recall":[0.3475957076727296],"average_precision_score_micro":[0.8787558338864634],"log_loss":[2.9133219680808424],"accuracy":[0.9001517450682853]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_29":{"norm_macro_recall":[0.4826589755986417],"AUC_micro":[0.9783323700553328],"average_precision_score_macro":[0.8085577541137163],"f1_score_macro":[0.7532324924087248],"matthews_correlation":[0.5077000526701819],"AUC_weighted":[0.9411963019151723],"recall_score_macro":[0.7413294877993208],"precision_score_weighted":[0.9022928077169412],"precision_score_macro":[0.7670201493317375],"f1_score_micro":[0.9065250379362669],"AUC_macro":[0.9411963019151723],"precision_score_micro":[0.906525037936267],"average_precision_score_micro":[0.9793590203488491],"balanced_accuracy":[0.7413294877993208],"weighted_accuracy":[0.9475386245712485],"recall_score_micro":[0.906525037936267],"log_loss":[0.18331567518136963],"accuracy":[0.906525037936267],"f1_score_weighted":[0.904163966769112],"recall_score_weighted":[0.906525037936267],"average_precision_score_weighted":[0.9512796793646534]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_0":{"AUC_macro":[0.9450464668693166],"AUC_weighted":[0.9450464668693167],"recall_score_weighted":[0.9116843702579667],"f1_score_weighted":[0.9091539479147899],"norm_macro_recall":[0.5026785366965085],"recall_score_macro":[0.7513392683482543],"precision_score_weighted":[0.9072720074188747],"recall_score_micro":[0.9116843702579667],"precision_score_micro":[0.9116843702579667],"log_loss":[0.17775706110025447],"average_precision_score_micro":[0.9806603102489483],"matthews_correlation":[0.5323740218566827],"AUC_micro":[0.979695082216353],"balanced_accuracy":[0.7513392683482543],"accuracy":[0.9116843702579667],"f1_score_micro":[0.9116843702579667],"precision_score_macro":[0.7819118765348991],"average_precision_score_weighted":[0.9531771295804466],"f1_score_macro":[0.7653697272147331],"weighted_accuracy":[0.9514937218005303],"average_precision_score_macro":[0.8151093723721079]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_36":{"average_precision_score_macro":[0.8214464126252905],"average_precision_score_micro":[0.9811946906654517],"precision_score_macro":[0.8027388130313766],"balanced_accuracy":[0.7435870718925919],"recall_score_macro":[0.7435870718925919],"accuracy":[0.9168437025796662],"recall_score_weighted":[0.9168437025796662],"AUC_macro":[0.9464653874153233],"norm_macro_recall":[0.48717414378518376],"weighted_accuracy":[0.9598586374667052],"recall_score_micro":[0.9168437025796662],"average_precision_score_weighted":[0.954714278142811],"precision_score_micro":[0.9168437025796662],"AUC_weighted":[0.9464653874153234],"precision_score_weighted":[0.910124239080319],"f1_score_micro":[0.9168437025796662],"f1_score_weighted":[0.9123493387706326],"log_loss":[0.18133519311874638],"matthews_correlation":[0.5431142090372958],"f1_score_macro":[0.768698235524393],"AUC_micro":[0.9802818912178981]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_8":{"precision_score_weighted":[0.8808507057124882],"average_precision_score_macro":[0.7446905881038663],"f1_score_macro":[0.5708498231439252],"AUC_weighted":[0.888478124357457],"recall_score_weighted":[0.896206373292868],"precision_score_macro":[0.8179269204512207],"accuracy":[0.896206373292868],"recall_score_macro":[0.5543473428582543],"AUC_macro":[0.8884781243574569],"average_precision_score_weighted":[0.9294040836398006],"norm_macro_recall":[0.10869468571650853],"matthews_correlation":[0.2628952897990485],"recall_score_micro":[0.896206373292868],"weighted_accuracy":[0.9810807234194759],"balanced_accuracy":[0.5543473428582543],"AUC_micro":[0.9655265599922632],"f1_score_weighted":[0.8608242737297903],"precision_score_micro":[0.896206373292868],"average_precision_score_micro":[0.9653423871385973],"f1_score_micro":[0.896206373292868],"log_loss":[0.26329333934784094]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_4":{"recall_score_weighted":[0.9010622154779969],"matthews_correlation":[0.41011936494883044],"log_loss":[0.33071245514121794],"precision_score_macro":[0.7607152588759832],"recall_score_micro":[0.9010622154779969],"accuracy":[0.9010622154779969],"average_precision_score_weighted":[0.9378807444499484],"precision_score_weighted":[0.8861494315538403],"AUC_macro":[0.9189534256928351],"norm_macro_recall":[0.32257009856496377],"AUC_micro":[0.9690996382526521],"f1_score_macro":[0.6946944357913836],"recall_score_macro":[0.6612850492824819],"f1_score_weighted":[0.8894830709551599],"average_precision_score_macro":[0.762583112800556],"f1_score_micro":[0.9010622154779969],"weighted_accuracy":[0.9605923999817423],"AUC_weighted":[0.9189534256928352],"balanced_accuracy":[0.6612850492824819],"precision_score_micro":[0.9010622154779969],"average_precision_score_micro":[0.9675704664728344]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_5":{"average_precision_score_weighted":[0.9292258632304623],"AUC_macro":[0.8938361239388197],"balanced_accuracy":[0.5932768914155307],"recall_score_macro":[0.5932768914155307],"recall_score_weighted":[0.9001517450682853],"average_precision_score_micro":[0.968292176719747],"precision_score_micro":[0.9001517450682853],"precision_score_weighted":[0.8827113977984437],"accuracy":[0.9001517450682853],"weighted_accuracy":[0.9763404704059276],"precision_score_macro":[0.7979300898726163],"norm_macro_recall":[0.1865537828310615],"average_precision_score_macro":[0.7330081507401955],"matthews_correlation":[0.33340661446628406],"recall_score_micro":[0.9001517450682853],"f1_score_macro":[0.6267831475663812],"AUC_weighted":[0.8938361239388196],"log_loss":[0.24950544016923687],"f1_score_weighted":[0.8746567304785686],"AUC_micro":[0.9667199808418973],"f1_score_micro":[0.9001517450682853]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_6":{"average_precision_score_macro":[0.7238188569698953],"average_precision_score_weighted":[0.9246945549980491],"weighted_accuracy":[0.9730611889183236],"precision_score_macro":[0.771526544069397],"recall_score_weighted":[0.8977238239757208],"recall_score_micro":[0.8977238239757208],"average_precision_score_micro":[0.9643907012047133],"precision_score_weighted":[0.877014103638037],"AUC_micro":[0.9637527775794935],"recall_score_macro":[0.5942781010175104],"f1_score_weighted":[0.8734704046383025],"log_loss":[0.2553805782822653],"norm_macro_recall":[0.18855620203502088],"f1_score_micro":[0.8977238239757208],"matthews_correlation":[0.31999379338174755],"AUC_weighted":[0.8790620305382821],"f1_score_macro":[0.6263947343363969],"balanced_accuracy":[0.5942781010175104],"accuracy":[0.8977238239757208],"AUC_macro":[0.8790620305382821],"precision_score_micro":[0.8977238239757208]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_7":{"precision_score_micro":[0.8992412746585736],"balanced_accuracy":[0.6863106583902476],"precision_score_weighted":[0.8881266134020223],"f1_score_weighted":[0.8920246315557786],"recall_score_macro":[0.6863106583902476],"AUC_macro":[0.9223344762497523],"average_precision_score_micro":[0.9635807320931392],"recall_score_weighted":[0.8992412746585736],"AUC_weighted":[0.9223344762497523],"matthews_correlation":[0.4306103598568124],"recall_score_micro":[0.8992412746585736],"precision_score_macro":[0.7488119622598568],"average_precision_score_weighted":[0.9373097414061812],"f1_score_micro":[0.8992412746585736],"average_precision_score_macro":[0.7550620463748294],"AUC_micro":[0.968005415848264],"accuracy":[0.8992412746585736],"log_loss":[0.23207422951390147],"weighted_accuracy":[0.9521061870022858],"f1_score_macro":[0.7111132941651193],"norm_macro_recall":[0.37262131678049526]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_13":{"average_precision_score_micro":[0.842751306312107],"AUC_macro":[0.8615292851493108],"recall_score_micro":[0.7699544764795144],"balanced_accuracy":[0.7733728260044049],"precision_score_micro":[0.7699544764795144],"matthews_correlation":[0.37910391147876826],"average_precision_score_weighted":[0.9229644847538927],"f1_score_weighted":[0.808254207566593],"accuracy":[0.7699544764795144],"log_loss":[0.5959331321220599],"AUC_micro":[0.8474922918571155],"AUC_weighted":[0.8615292851493108],"recall_score_weighted":[0.7699544764795144],"f1_score_macro":[0.6433848264392198],"norm_macro_recall":[0.5467456520088099],"precision_score_weighted":[0.8901624188661584],"average_precision_score_macro":[0.7272975991290862],"precision_score_macro":[0.6314320243521443],"recall_score_macro":[0.7733728260044049],"f1_score_micro":[0.7699544764795144],"weighted_accuracy":[0.7691057927572742]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_18":{"AUC_weighted":[0.9057334763368141],"average_precision_score_micro":[0.8647080222244536],"AUC_macro":[0.9057334763368141],"average_precision_score_macro":[0.7591046766066786],"balanced_accuracy":[0.8309261698221904],"recall_score_micro":[0.8364188163884674],"f1_score_micro":[0.8364188163884674],"accuracy":[0.8364188163884674],"precision_score_macro":[0.6824605535826814],"AUC_micro":[0.8924061609879317],"precision_score_micro":[0.8364188163884674],"weighted_accuracy":[0.8377824919572983],"f1_score_macro":[0.7155260966430093],"matthews_correlation":[0.49145079973789163],"recall_score_macro":[0.8309261698221904],"log_loss":[0.43273276283619755],"recall_score_weighted":[0.8364188163884674],"f1_score_weighted":[0.8594379608837617],"average_precision_score_weighted":[0.9357730858657888],"precision_score_weighted":[0.9088385167766978],"norm_macro_recall":[0.6618523396443807]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_16":{"log_loss":[0.4923330104785799],"AUC_macro":[0.8872180451127819],"accuracy":[0.7220030349013657],"f1_score_macro":[0.6203496855345911],"precision_score_macro":[0.6302870767673082],"matthews_correlation":[0.39906459571455666],"balanced_accuracy":[0.8055800995467234],"average_precision_score_macro":[0.7405605644845225],"AUC_weighted":[0.8872180451127819],"recall_score_micro":[0.7220030349013657],"precision_score_micro":[0.7220030349013657],"recall_score_macro":[0.8055800995467234],"average_precision_score_weighted":[0.9299304176465014],"recall_score_weighted":[0.7220030349013657],"AUC_micro":[0.8502085055528562],"average_precision_score_micro":[0.8637887615204101],"norm_macro_recall":[0.6111601990934468],"f1_score_micro":[0.7220030349013657],"precision_score_weighted":[0.9052199078913233],"f1_score_weighted":[0.7727998992183698],"weighted_accuracy":[0.7012531104712695]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_23":{"f1_score_weighted":[0.7876543160473797],"average_precision_score_macro":[0.7010279938165735],"norm_macro_recall":[0.472356982626559],"weighted_accuracy":[0.745760026545141],"AUC_micro":[0.8188628100239246],"AUC_macro":[0.8085971580836793],"precision_score_weighted":[0.8784298502241077],"AUC_weighted":[0.8085971580836793],"recall_score_micro":[0.7438543247344461],"balanced_accuracy":[0.7361784913132795],"precision_score_micro":[0.7438543247344461],"recall_score_weighted":[0.7438543247344461],"average_precision_score_weighted":[0.9051836652002695],"f1_score_micro":[0.7438543247344462],"f1_score_macro":[0.6132048179365213],"average_precision_score_micro":[0.7856087808181988],"log_loss":[0.5670894986665442],"matthews_correlation":[0.32299593459703296],"recall_score_macro":[0.7361784913132795],"accuracy":[0.7438543247344461],"precision_score_macro":[0.6104317048369858]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_24":{"recall_score_micro":[0.8995447647951441],"f1_score_weighted":[0.8722950091956113],"matthews_correlation":[0.3218684594572277],"average_precision_score_micro":[0.963556237344063],"precision_score_micro":[0.8995447647951441],"f1_score_macro":[0.6170656133421111],"accuracy":[0.8995447647951441],"recall_score_macro":[0.5858303371140341],"AUC_micro":[0.9629623216304651],"average_precision_score_weighted":[0.9270444511277971],"weighted_accuracy":[0.9774315713566799],"AUC_macro":[0.8749821708743404],"recall_score_weighted":[0.8995447647951441],"log_loss":[0.2576112069577068],"f1_score_micro":[0.8995447647951441],"AUC_weighted":[0.8749821708743404],"average_precision_score_macro":[0.7386110419892948],"norm_macro_recall":[0.1716606742280682],"precision_score_macro":[0.8017560826299885],"balanced_accuracy":[0.5858303371140341],"precision_score_weighted":[0.8823379905566089]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_3":{"recall_score_macro":[0.8470636124679771],"precision_score_weighted":[0.9143627352030754],"average_precision_score_macro":[0.7569736090120975],"AUC_weighted":[0.9183740948824389],"f1_score_weighted":[0.8689528074365016],"recall_score_weighted":[0.8482549317147192],"recall_score_micro":[0.8482549317147192],"f1_score_macro":[0.7318427861396168],"AUC_micro":[0.9130072925133728],"weighted_accuracy":[0.848550704059045],"accuracy":[0.8482549317147192],"precision_score_micro":[0.8482549317147192],"f1_score_micro":[0.8482549317147192],"balanced_accuracy":[0.8470636124679771],"norm_macro_recall":[0.6941272249359542],"average_precision_score_micro":[0.8908762801063387],"AUC_macro":[0.9183740948824388],"precision_score_macro":[0.6954020441153466],"average_precision_score_weighted":[0.937242318128663],"log_loss":[0.3847613390603274],"matthews_correlation":[0.5208337136334367]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_26":{"recall_score_weighted":[0.9050075872534142],"accuracy":[0.9050075872534142],"balanced_accuracy":[0.677716093633937],"recall_score_micro":[0.9050075872534142],"f1_score_micro":[0.9050075872534142],"average_precision_score_macro":[0.7796888442678398],"precision_score_macro":[0.7743966616900909],"matthews_correlation":[0.4416546289659192],"average_precision_score_micro":[0.975683103000264],"weighted_accuracy":[0.961437916988258],"average_precision_score_weighted":[0.9434194883740251],"f1_score_weighted":[0.8949073548292011],"precision_score_weighted":[0.8920339060245107],"log_loss":[0.20753267617928065],"AUC_micro":[0.974526907693406],"AUC_weighted":[0.9284598228757408],"norm_macro_recall":[0.35543218726787407],"recall_score_macro":[0.677716093633937],"precision_score_micro":[0.9050075872534142],"AUC_macro":[0.9284598228757408],"f1_score_macro":[0.7117421469659885]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_9":{"f1_score_macro":[0.6558008917865913],"recall_score_micro":[0.8959028831562974],"average_precision_score_micro":[0.9696871226543725],"precision_score_macro":[0.7442611600319673],"log_loss":[0.24195783137072702],"accuracy":[0.8959028831562974],"precision_score_weighted":[0.8758349252267118],"norm_macro_recall":[0.24571221105239083],"recall_score_weighted":[0.8959028831562974],"f1_score_weighted":[0.8788898423434004],"precision_score_micro":[0.8959028831562974],"AUC_macro":[0.914729543741097],"matthews_correlation":[0.34646197397600953],"weighted_accuracy":[0.9636930122514887],"average_precision_score_weighted":[0.9392811673128828],"recall_score_macro":[0.6228561055261954],"average_precision_score_macro":[0.768546152888198],"f1_score_micro":[0.8959028831562974],"AUC_micro":[0.9703306384575885],"balanced_accuracy":[0.6228561055261954],"AUC_weighted":[0.914729543741097]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_19":{"accuracy":[0.8880121396054628],"AUC_weighted":[0.8670549248212922],"matthews_correlation":[0.0],"recall_score_macro":[0.5],"recall_score_micro":[0.8880121396054628],"f1_score_micro":[0.8880121396054628],"weighted_accuracy":[0.9843450583187134],"balanced_accuracy":[0.5],"f1_score_macro":[0.4703423886834914],"norm_macro_recall":[0.0],"f1_score_weighted":[0.8353395018439429],"log_loss":[0.2727175536567054],"average_precision_score_macro":[0.6865101760194318],"precision_score_weighted":[0.788565560086672],"precision_score_micro":[0.8880121396054628],"AUC_macro":[0.867054924821292],"average_precision_score_micro":[0.9620707527835073],"AUC_micro":[0.9610168531434715],"recall_score_weighted":[0.8880121396054628],"average_precision_score_weighted":[0.9150711018886352],"precision_score_macro":[0.4440060698027314]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_12":{"AUC_micro":[0.9717046796889571],"matthews_correlation":[0.3446963268418708],"AUC_weighted":[0.9158895946444086],"precision_score_weighted":[0.8832720209144211],"recall_score_weighted":[0.9007587253414264],"precision_score_macro":[0.7949054137605622],"f1_score_micro":[0.9007587253414264],"recall_score_micro":[0.9007587253414264],"weighted_accuracy":[0.9752493694551752],"average_precision_score_micro":[0.9721510586036974],"precision_score_micro":[0.9007587253414264],"recall_score_macro":[0.6007234457170272],"balanced_accuracy":[0.6007234457170272],"AUC_macro":[0.9158895946444086],"f1_score_weighted":[0.8769304961924207],"accuracy":[0.9007587253414264],"norm_macro_recall":[0.20144689143405436],"average_precision_score_macro":[0.7670227597909847],"f1_score_macro":[0.6361052711568176],"log_loss":[0.2505919548837528],"average_precision_score_weighted":[0.9386427714880295]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_25":{"f1_score_weighted":[0.9105214923382681],"average_precision_score_macro":[0.8117468850807403],"precision_score_weighted":[0.908739808485468],"average_precision_score_weighted":[0.9518344397613885],"norm_macro_recall":[0.5111503814969796],"AUC_micro":[0.9782576718760432],"accuracy":[0.9128983308042489],"matthews_correlation":[0.5398649524892071],"precision_score_macro":[0.7850963018677666],"f1_score_micro":[0.9128983308042489],"precision_score_micro":[0.9128983308042489],"f1_score_macro":[0.7691825165821541],"recall_score_macro":[0.7555751907484898],"recall_score_weighted":[0.9128983308042489],"recall_score_micro":[0.9128983308042489],"AUC_weighted":[0.9402691873808691],"weighted_accuracy":[0.951957410961161],"log_loss":[0.19211075143224646],"average_precision_score_micro":[0.9792423403521983],"balanced_accuracy":[0.7555751907484898],"AUC_macro":[0.9402691873808691]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_11":{"recall_score_micro":[0.8555386949924128],"norm_macro_recall":[0.6952247581259134],"log_loss":[0.7995622318418177],"AUC_weighted":[0.9209155557037457],"balanced_accuracy":[0.8476123790629567],"AUC_macro":[0.9209155557037457],"matthews_correlation":[0.5292245821591193],"precision_score_weighted":[0.915010337111045],"f1_score_weighted":[0.8743646721874818],"recall_score_macro":[0.8476123790629567],"recall_score_weighted":[0.8555386949924128],"weighted_accuracy":[0.8575065848344788],"average_precision_score_macro":[0.7528472144589519],"average_precision_score_weighted":[0.9364547128389856],"f1_score_micro":[0.8555386949924128],"f1_score_macro":[0.7391455045251458],"average_precision_score_micro":[0.9110096930579747],"precision_score_micro":[0.8555386949924128],"AUC_micro":[0.9212430661253888],"precision_score_macro":[0.7014302965248893],"accuracy":[0.8555386949924128]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_15":{"matthews_correlation":[0.3100790852854497],"precision_score_micro":[0.898937784522003],"precision_score_weighted":[0.8822139344502697],"average_precision_score_micro":[0.9728293681949642],"f1_score_weighted":[0.8698394838963456],"AUC_micro":[0.9714521243158231],"log_loss":[0.215148404004578],"AUC_weighted":[0.9170941025883258],"f1_score_macro":[0.6069265697627556],"weighted_accuracy":[0.9785226723074326],"AUC_macro":[0.9170941025883259],"f1_score_micro":[0.8989377845220029],"accuracy":[0.898937784522003],"average_precision_score_macro":[0.7613884675196837],"average_precision_score_weighted":[0.9381325671931131],"norm_macro_recall":[0.1567675656250751],"precision_score_macro":[0.8066611347445773],"recall_score_micro":[0.898937784522003],"balanced_accuracy":[0.5783837828125376],"recall_score_weighted":[0.898937784522003],"recall_score_macro":[0.5783837828125376]},"e43986a8-c19e-48d8-bbda-d20dbf02b494_21":{"average_precision_score_macro":[0.714661874127579],"average_precision_score_weighted":[0.914045758398616],"weighted_accuracy":[0.7093879636503571],"norm_macro_recall":[0.45407495086570826],"average_precision_score_micro":[0.7931509236810447],"recall_score_micro":[0.7128983308042489],"f1_score_weighted":[0.7642725876086041],"AUC_macro":[0.8332022776823804],"AUC_weighted":[0.8332022776823804],"f1_score_micro":[0.7128983308042488],"recall_score_weighted":[0.7128983308042489],"f1_score_macro":[0.5909691909743874],"precision_score_macro":[0.60032635707901],"precision_score_micro":[0.7128983308042489],"precision_score_weighted":[0.8768359985923969],"matthews_correlation":[0.3018466023038423],"AUC_micro":[0.8106848791450697],"log_loss":[0.5498417975990353],"accuracy":[0.7128983308042489],"balanced_accuracy":[0.7270374754328541],"recall_score_macro":[0.7270374754328541]}}